可以说是深度学习的开山之作，用全新的CNN改变了既有特征提取+分类的方法。
特征提取+分类方法需要人工手动设计特征提取器，识别图像中特定的符号和形状。这一过程费时费力，需要专业人士的大量工作，且泛化性能差。
本文中提到的许多方法，现在已经是机器学习和深度学习领域的基础知识了，在此简单提及：

* 卷积：函数的二元运算，输出其“对角线组合”的结果。
	对于离散情况而言（例如投两个骰子，计算点数和为X的概率），可以理解为：其中一个随机序列翻转，进行滑窗+相乘求和，或者列成二维表格，依次对次对角线方向求和
	对于连续情况，可将两个变量的概率分布化为二维函数图像，沿对角线方向的切面$/\sqrt{2}$得到
	可参考3B1B的视频讲解
	在CV领域，是图像按像素分割，每个像素有一个值（灰度图像的灰度值，RGB图像每个通道的颜色值等），卷积是取一个小矩阵（卷积核），与图片对应位置矩阵相乘再求和，得到的结果映射到新图片的一个像素。卷积核会在原图上滑动，直到遍历整个图像

* 图像卷积的几个概念和参数
	* 通道(channel)：可以将卷积的输入输出视作一个立方体：图片的长 宽 通道数，通道数指示一个图像的一个像素有多少个参数特征。例如RGB图像每个像素有红绿蓝三色，因此有三通道
	* 卷积核：进行卷积的小矩阵，不同类型的卷积核可以提取不同的特征（如水平，数值方向的边缘等）
	* 感受野(kernel_size)：卷积核的大小，一般是3*3，5*5这样的奇数大小正方形
	* 步长(stride)：卷积核每次移动多少个像素，大步长可以迅速拉近远距离的特征，降低图像尺寸，但是会使得特征提取稀疏
	* 填充（padding）：在原图像的边缘或者内部填充值，调整尺寸便于卷积。通常是填充0，但也有填充其他常数、按周边值递增/递减，镜像等多种方式

* 池化(pooling)
	下采样（降低图片尺寸和分辨率）的一种。选取某个范围内的像素，以其中的最大值/平均值之类的统计量代替各自的值，压缩到一个像素。
	池化会丢失信息，但很大降低了参数量，提高训练效率，除此之外还能降低过拟合，同时将局部的特征更紧密地联系在一起
	池化操作可行的原因，来自于图像处理的特征：
		* **局部相似性**：通常而言，图像某处的像素和周围的像素类似，压缩不会损失太多的信息
		* **不变性**：图像的特征经过平移，旋转，尺度的变换之后，位置信息一定程度上保持不变
		* **特征冗余**：图像处理的大部分信息是冗余的，池化可以消除这些信息量，让模型专注于更宏观显著的特征

* 正则化(Normalization)
	抑制过拟合的一种手段
	学习的各个参数乘以一个超参数，限制了参数的取值，例如参数w正常训练取值为12，通过对其乘一个超参数$\beta = 1000$，w的值变为0.012，能取的值变小了

* 全连接层
	通常是CNN的最后一部分，将先前提取到的特征全部融合起来，通过激活函数进行非线性映射，最后根据任务目标进行分类
	将前一层的特征展平为一维向量，输出向量数一般为目标类别个数，每个输入都和所有的输出连接
	相当经典的y=f(wx+b)的运算过程
	全连接层的参数量一般很大，占整个网络的半数以上
	
	




import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms

# 模型定义部分，包括结构和前向传播过程
class LeNet5(nn.Module):
    def __init__(self, num_classes):
        super(LeNet5, self).__init__()
        # 卷积层，下同
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),
            nn.BatchNorm2d(6),		# 更现代化的批量归一化
            nn.ReLU(),)
        # 下采样（最大池化），下同
        self.subsampel1 = nn.MaxPool2d(kernel_size = 2, stride = 2)
        
        self.layer2 = nn.Sequential(
            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),
            nn.BatchNorm2d(16),
            nn.ReLU(),)
        
        self.subsampel2 = nn.MaxPool2d(kernel_size = 2, stride = 2)
        # 全连接
        self.L1 = nn.Linear(400, 120)
        self.relu = nn.ReLU()
        self.L2 = nn.Linear(120, 84)
        self.relu1 = nn.ReLU()
        self.L3 = nn.Linear(84, num_classes)
    # 前向传播
    def forward(self, x):
        out = self.layer1(x)
        out = self.subsampel1(out)
        out = self.layer2(out)
        out = self.subsampel2(out)
        # 将上一步输出的16个5×5特征图中的400个像素展平成一维向量，以便下一步全连接
        out = out.reshape(out.size(0), -1)
        # 全连接
        out = self.L1(out)
        out = self.relu(out)
        out = self.L2(out)
        out = self.relu1(out)
        out = self.L3(out)
        return out

# 加载训练集
train_dataset = torchvision.datasets.MNIST(root = './data',
                                           train = True,
                                           transform = transforms.Compose([
                                                  transforms.Resize((32,32)),
                                                  transforms.ToTensor(),
                                                  transforms.Normalize(mean = (0.1307,), 
												                     std = (0.3081,))]), # 重设大小，转为张量，归一化，参数是测试出来的
                                           download = True)
 
# 加载测试集
test_dataset = torchvision.datasets.MNIST(root = './data',
                                          train = False,
                                          transform = transforms.Compose([
                                                  transforms.Resize((32,32)),
                                                  transforms.ToTensor(),
                                                  transforms.Normalize(mean = (0.1325,), 
												                     std = (0.3105,))]),
                                          download=True)

batch_size = 64
# 加载训练数据
train_loader = torch.utils.data.DataLoader(dataset = train_dataset,
                                           batch_size = batch_size,
                                           shuffle = True)
# 加载测试数据
test_loader = torch.utils.data.DataLoader(dataset = test_dataset,
                                           batch_size = batch_size,
                                           shuffle = False)	

# 训练集打乱而测试集不打乱，降低过拟合，提高效率

num_classes = 10
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = LeNet5(num_classes).to(device)
cost = nn.CrossEntropyLoss()
learning_rate = 0.001
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
total_step = len(train_loader)
num_epochs = 10 #遍历测试集轮次

# 定义训练流程
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):  
        images = images.to(device)
        labels = labels.to(device)
 
        # 前向传播
        outputs = model(images)
        loss = cost(outputs, labels)
 
        # 反向传播
        optimizer.zero_grad()	# 清零梯度，避免累计
        loss.backward()		# 反向传播
        optimizer.step()	# 更新模型参数
 
        # 定期输出训练信息
        if (i+1) % 400 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
        		           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))

with torch.no_grad():
    
    correct = 0		# 正确分类的样本数
    total = 0		# 总样本数
 
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
 
        # 模型预测
        outputs = model(images)
 
        # 计算准确率
        # 从模型输出中获取每个样本预测的类别
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
 
    # 输出准确率
    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))
    
